import streamlit as st
import pandas as pd
from langchain.docstore.document import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_pinecone import PineconeVectorStore
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import RetrievalQA
from pinecone import Pinecone, ServerlessSpec
import os
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ì„¤ì •
PINECONE_INDEX_NAME = "samsung-rag"
PINECONE_DIMENSION = 1536
PINECONE_REGION = "us-east-1"
PINECONE_CLOUD = "aws"
EMBEDDING_MODEL = "text-embedding-3-small"

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_PROMPT = """
ë„ˆëŠ” ê¸°ì—…ì˜ ê³µì‹œë¬¸ì„œ(ì˜ˆ: ë¶„ê¸°ë³´ê³ ì„œ, ì‚¬ì—…ë³´ê³ ì„œ, ê°ì‚¬ë³´ê³ ì„œ ë“±)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ê·¼ê±° ìˆëŠ” ë‹µë³€ì„ ì œê³µí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì´ì
ê¸°ì—…ì˜ í˜„í™©ê³¼ íë¦„ì„ ì•Œë ¤ì£¼ëŠ” ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì•¼.

ì§€ì¼œì•¼ í•  ì›ì¹™:
- ë°˜ë“œì‹œ ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ë§Œ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•´. ì¶”ì¸¡í•˜ì§€ ë§ˆ.
- ìˆ«ìë‚˜ ìˆ˜ì¹˜ëŠ” ë¬¸ì„œì—ì„œ ì§ì ‘ ì¸ìš©í•˜ê³ , ë‹¨ìœ„ë¥¼ í¬í•¨í•´ì¤˜.
- ë¬¸ì„œì— ê·¼ê±°ê°€ ì—†ìœ¼ë©´ "í•´ë‹¹ ì •ë³´ëŠ” ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µë³€í•´.
- ê°€ëŠ¥í•œ ê²½ìš°, ë¬¸ì„œì˜ ì¶œì²˜(ex. í˜ì´ì§€ ë²ˆí˜¸ or ë¬¸ë‹¨ ë‚´ìš©)ë¥¼ í•¨ê»˜ í¬í•¨í•´.
- ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ë¡œ ëŒ€ë‹µí•˜ì§€ë§ˆ
- ì´ˆê¸‰ ì¤‘ê¸‰ì— ë‚˜ëˆ ì„œ ê°ê° ì´ˆë“±í•™ìƒìˆ˜ì¤€ ì¼ë°˜ì¸ ìˆ˜ì¤€ìœ¼ë¡œ ì„¤ëª…ì„ í•´ì¤˜

ğŸ§¾ ì˜ˆì‹œ:
"2025ë…„ 1ë¶„ê¸° ì‚¼ì„±ì „ìì˜ ë§¤ì¶œì´ì´ìµì€ ì•½ 20ì¡° ì›ì´ë©°, ì´ëŠ” 2024ë…„ ë™ê¸° ëŒ€ë¹„ 8% ì¦ê°€í•œ ìˆ˜ì¹˜ì…ë‹ˆë‹¤. (ì¶œì²˜: 3í˜ì´ì§€)"

ëª©í‘œëŠ” **ì •í™•ì„±, íˆ¬ëª…ì„±, ì‹ ë¢°ë„**ë¥¼ ê°–ì¶˜ ë‹µë³€ì´ì•¼.
"""


@st.cache_resource
def initialize_pinecone():
    """Pinecone ì´ˆê¸°í™”"""
    return Pinecone(api_key=os.environ["PINECONE_API_KEY"])


@st.cache_resource
def setup_vector_store():
    """ë²¡í„° ìŠ¤í† ì–´ ì„¤ì •"""
    pc = initialize_pinecone()
    embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)
    index = pc.Index(PINECONE_INDEX_NAME)
    return PineconeVectorStore(index=index, embedding=embeddings)


@st.cache_resource
def setup_qa_chain():
    """QA ì²´ì¸ ì„¤ì •"""
    vector_store = setup_vector_store()

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = ChatPromptTemplate.from_messages([
        ("system", SYSTEM_PROMPT),
        ("user", "{question}"),
        ("system", "ê´€ë ¨ ë¬¸ì„œ:\n{context}")
    ])

    # LLM êµ¬ì„±
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0,
        api_key=os.environ["OPENAI_API_KEY"]
    )

    # QA ì²´ì¸ ìƒì„±
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=vector_store.as_retriever(search_kwargs={"k": 3}),
        chain_type="stuff",
        chain_type_kwargs={"prompt": prompt}
    )

    return qa_chain, vector_store


def get_pinecone_stats():
    """Pinecone ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    try:
        pc = initialize_pinecone()
        index = pc.Index(PINECONE_INDEX_NAME)
        stats = index.describe_index_stats()
        return stats
    except Exception as e:
        st.error(f"Pinecone ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        return None


def main():
    st.title("ğŸ¢ ì‹œì´50ê¸°ì—… ê³µì‹œë¬¸ì„œ RAG ì‹œìŠ¤í…œ")
    st.markdown("---")

    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ì‹œìŠ¤í…œ ì •ë³´")

        # Pinecone ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ
        st.subheader("ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ")

        try:
            stats = get_pinecone_stats()
            if stats:
                st.success("âœ… Pinecone ì—°ê²° ì„±ê³µ")
                st.write(f"**ì¸ë±ìŠ¤ëª…**: {PINECONE_INDEX_NAME}")
                st.write(f"**ì´ ë²¡í„° ìˆ˜**: {stats.total_vector_count:,}")
                st.write(f"**ì°¨ì›**: {stats.dimension}")

                # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì •ë³´
                if hasattr(stats, 'namespaces') and stats.namespaces:
                    st.write("**ë„¤ì„ìŠ¤í˜ì´ìŠ¤**:")
                    for namespace, info in stats.namespaces.items():
                        if namespace == "":
                            namespace = "ê¸°ë³¸"
                        st.write(f"  - {namespace}: {info.vector_count:,}ê°œ")
            else:
                st.error("âŒ Pinecone ì—°ê²° ì‹¤íŒ¨")

        except Exception as e:
            st.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}")

        st.markdown("---")

        # ì‹œìŠ¤í…œ ì„¤ì • ì •ë³´
        st.subheader("ğŸ”§ ì‹œìŠ¤í…œ ì„¤ì •")
        st.write(f"**ì„ë² ë”© ëª¨ë¸**: {EMBEDDING_MODEL}")
        st.write(f"**ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜**: 3ê°œ")
        st.write(f"**LLM ëª¨ë¸**: gpt-4o-mini")

        # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
        if st.button("ğŸ”„ ìƒíƒœ ìƒˆë¡œê³ ì¹¨"):
            st.cache_resource.clear()
            st.rerun()

    # ë©”ì¸ ì»¨í…ì¸ 
    st.header("ğŸ’¬ ì§ˆë¬¸í•˜ê¸°")

    # ì˜ˆì‹œ ì§ˆë¬¸ë“¤
    example_questions = [
        "ì‚¼ì„±ì „ì ë§¤ì¶œì´ì´ìµì€?",
        "í˜„ëŒ€ í¬ìŠ¤ì½”ì˜ GM Battery Raw Materials Corporationê³¼ ì–´ë–¤ ì•½ì •ì´ ìˆë‚˜ìš”?",
        "2024ë…„ ì£¼ìš” ì¬ë¬´ì§€í‘œëŠ”?",
        "ìµœê·¼ íˆ¬ì í˜„í™©ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
    ]

    st.subheader("ğŸ” ì˜ˆì‹œ ì§ˆë¬¸")
    cols = st.columns(2)
    for i, question in enumerate(example_questions):
        with cols[i % 2]:
            if st.button(question, key=f"example_{i}"):
                st.session_state.question = question

    # ì§ˆë¬¸ ì…ë ¥
    question = st.text_input(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
        value=st.session_state.get('question', ''),
        placeholder="ì˜ˆ: ì‚¼ì„±ì „ìì˜ 2024ë…„ ë§¤ì¶œì€ ì–¼ë§ˆì¸ê°€ìš”?"
    )

    if st.button("ğŸ” ê²€ìƒ‰", type="primary"):
        if question:
            try:
                # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
                with st.spinner("ì‹œìŠ¤í…œ ì—°ê²° í™•ì¸ ì¤‘..."):
                    stats = get_pinecone_stats()
                    if not stats or stats.total_vector_count == 0:
                        st.error("âŒ ë°ì´í„°ë² ì´ìŠ¤ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
                        return

                with st.spinner("ë‹µë³€ì„ ìƒì„±ì¤‘ì…ë‹ˆë‹¤..."):
                    qa_chain, vector_store = setup_qa_chain()

                    # ê²€ìƒ‰ ê²°ê³¼ ë¨¼ì € í‘œì‹œ
                    st.subheader("ğŸ“‹ ê´€ë ¨ ë¬¸ì„œ")
                    retriever = vector_store.as_retriever(search_kwargs={"k": 3})
                    results = retriever.invoke(question)

                    if not results:
                        st.warning("ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì‹œë„í•´ë³´ì„¸ìš”.")
                        return

                    for i, result in enumerate(results, 1):
                        with st.expander(f"ğŸ“„ ë¬¸ì„œ {i} (ìœ ì‚¬ë„ ì ìˆ˜ ê¸°ì¤€)"):
                            st.write(result.page_content)

                    # QA ê²°ê³¼
                    st.subheader("ğŸ¤– AI ë‹µë³€")
                    answer = qa_chain.run(question)

                    # ë‹µë³€ì„ ë” ë³´ê¸° ì¢‹ê²Œ í‘œì‹œ
                    st.markdown("---")
                    st.write(answer)

                    # ì‹ ë¢°ë„ ì•ˆë‚´
                    st.info("ğŸ’¡ ì´ ë‹µë³€ì€ ìœ„ì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                st.write("**ê°€ëŠ¥í•œ ì›ì¸:**")
                st.write("- í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì˜¤ë¥˜")
                st.write("- API í‚¤ ë§Œë£Œ ë˜ëŠ” í• ë‹¹ëŸ‰ ì´ˆê³¼")
                st.write("- ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ")
                st.write("- Pinecone ì¸ë±ìŠ¤ ì ‘ê·¼ ë¬¸ì œ")
        else:
            st.warning("â— ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    # í•˜ë‹¨ ì •ë³´
    st.markdown("---")

    # ì‹œìŠ¤í…œ ì •ë³´
    col1, col2 = st.columns(2)

    with col1:
        st.info("ğŸ’¡ **ì‹œìŠ¤í…œ íŠ¹ì§•**\n"
                "- ê³µì‹œë¬¸ì„œ ê¸°ë°˜ ì •í™•í•œ ì •ë³´ ì œê³µ\n"
                "- ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ë‹µë³€í•˜ì§€ ì•ŠìŒ\n"
                "- ì‹¤ì‹œê°„ ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°")

    with col2:
        st.success("âœ… **ë°ì´í„°ë² ì´ìŠ¤ ì¤€ë¹„ ì™„ë£Œ**\n"
                   "- ì‚¼ì„±ì „ì í†µí•© ì‚¬ì—…ë³´ê³ ì„œ (2022-2024)\n"
                   "- ë²¡í„° ì„ë² ë”© ì™„ë£Œ\n"
                   "- ì¦‰ì‹œ ê²€ìƒ‰ ê°€ëŠ¥")

    # ì‚¬ìš© íŒ
    with st.expander("ğŸ“ ì‚¬ìš© íŒ"):
        st.write("""
        **íš¨ê³¼ì ì¸ ì§ˆë¬¸ ë°©ë²•:**
        1. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ë°ì´í„°ë¥¼ ìš”ì²­í•˜ì„¸ìš”
        2. íŠ¹ì • ì—°ë„ë‚˜ ê¸°ê°„ì„ ëª…ì‹œí•˜ì„¸ìš”
        3. íšŒì‚¬ëª…ì´ë‚˜ ì‚¬ì—… ë¶€ë¬¸ì„ ì •í™•íˆ ê¸°ì¬í•˜ì„¸ìš”

        **ì˜ˆì‹œ:**
        - âœ… "2024ë…„ ì‚¼ì„±ì „ì ë§¤ì¶œì•¡ì€ ì–¼ë§ˆì¸ê°€ìš”?"
        - âœ… "ë°˜ë„ì²´ ì‚¬ì—…ë¶€ì˜ ì˜ì—…ì´ìµ ì¶”ì´ëŠ”?"
        - âŒ "ì‚¼ì„±ì´ ì–´ë–¤ íšŒì‚¬ì¸ê°€ìš”?" (ë„ˆë¬´ ì¼ë°˜ì )
        """)

    # ì €ì‘ê¶Œ ì •ë³´
    st.caption("ğŸ“‹ ë³¸ ì‹œìŠ¤í…œì€ ê³µê°œëœ ì‚¬ì—…ë³´ê³ ì„œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, íˆ¬ì íŒë‹¨ì˜ ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")


if __name__ == "__main__":
    main()