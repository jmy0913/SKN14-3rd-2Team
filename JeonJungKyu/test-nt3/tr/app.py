import streamlit as st
import pandas as pd
from langchain.docstore.document import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_pinecone import PineconeVectorStore
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import RetrievalQA
from pinecone import Pinecone, ServerlessSpec
import os
from dotenv import load_dotenv
from utils.corp_search import run_flexible_rag

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

EMBEDDING_MODEL = 'BAAI/bge-m3'


st.title("ğŸ¢ ê¸°ì—… ì¬ë¬´ì œí‘œ, ì‚¬ì—…ë³´ê³ ì„œ RAG ì‹œìŠ¤í…œ")
st.markdown("---")

    # ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì‹œìŠ¤í…œ ì •ë³´")

        # ì‹œìŠ¤í…œ ì„¤ì • ì •ë³´
    st.subheader("ğŸ”§ ì‹œìŠ¤í…œ ì„¤ì •")
    st.write(f"**ì„ë² ë”© ëª¨ë¸**: {EMBEDDING_MODEL}")
    st.write(f"**LLM ëª¨ë¸**: gpt-4o-mini")

        # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
    if st.button("ğŸ”„ ìƒíƒœ ìƒˆë¡œê³ ì¹¨"):
        st.cache_resource.clear()
        st.rerun()

    # ë©”ì¸ ì»¨í…ì¸ 
st.header("ğŸ’¬ ì§ˆë¬¸í•˜ê¸°")

    # ì˜ˆì‹œ ì§ˆë¬¸ë“¤
example_questions = [
        "ì‚¼ì„±ì „ì ë§¤ì¶œì´ì´ìµì€?",
        "í˜„ëŒ€ í¬ìŠ¤ì½”ì˜ GM Battery Raw Materials Corporationê³¼ ì–´ë–¤ ì•½ì •ì´ ìˆë‚˜ìš”?",
        "2024ë…„ ì¹´ì¹´ì˜¤ì˜ ì£¼ìš” ì¬ë¬´ì§€í‘œëŠ”?",
        "ìµœê·¼ íˆ¬ì í˜„í™©ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
    ]

st.subheader("ğŸ” ì˜ˆì‹œ ì§ˆë¬¸")
cols = st.columns(2)
for i, question in enumerate(example_questions):
    with cols[i % 2]:
        if st.button(question, key=f"example_{i}"):
            st.session_state.question = question

    # ì§ˆë¬¸ ì…ë ¥
question = st.text_input(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
        value=st.session_state.get('question', ''),
        placeholder="ì˜ˆ: ì‚¼ì„±ì „ìì˜ 2024ë…„ ë§¤ì¶œì€ ì–¼ë§ˆì¸ê°€ìš”?"
    )

if st.button("ğŸ” ê²€ìƒ‰", type="primary"):
    if question:
        try:
            with st.spinner("ë‹µë³€ì„ ìƒì„±ì¤‘ì…ë‹ˆë‹¤..."):

                    # QA ê²°ê³¼
                st.subheader("ğŸ¤– AI ë‹µë³€")
                answer = run_flexible_rag(question)

                    # ë‹µë³€ì„ ë” ë³´ê¸° ì¢‹ê²Œ í‘œì‹œ
                st.markdown("---")
                st.write(answer)

        except Exception as e:
            st.write(e)


